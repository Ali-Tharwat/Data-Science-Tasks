{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Team Members and IDs:\n",
        "**Michael Danial** 13004528, **Ali Tharwat** 13004222, **Sherif Tamer** 13004065\n"
      ],
      "metadata": {
        "id": "EhClIv3Mpu7c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We Couldnt use the same dataset as Milestone 1\n",
        "\n",
        "Due to the fact that the **Loan Approval** dataset does not include the loan approval decision\n",
        "\n",
        "according to the dataset provider :\n",
        "https://www.kaggle.com/datasets/suryadeepthi/loan-approval-dataset/data\n",
        "\n",
        "as its written in  **About Dataset** section :\n",
        "This dataset provides a realistic simulation of loan applications, containing 5000 entries and 15 features that reflect key factors influencing loan approvals. It is designed for exploratory data analysis (EDA), feature engineering, and machine learning modeling.\n",
        "\n",
        "The dataset **does not include the loan approval decision**, allowing users to build their own prediction models.\n",
        "\n",
        "# We used the **Employee Attrition Prediction Dataset** Instead :\n",
        "https://www.kaggle.com/datasets/ziya07/employee-attrition-prediction-dataset/data"
      ],
      "metadata": {
        "id": "QVjWObsq1WMs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data Preparation :"
      ],
      "metadata": {
        "id": "YiiWbkGStWWa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULIPWxbAlXVA",
        "outputId": "b6683572-87a8-4f98-dec5-61c2e0469ae1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Dataset Shape: (1000, 26)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/employee_attrition_dataset.csv')\n",
        "print(\"Initial Dataset Shape:\", df.shape) # Number of Rows & Number of Columns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#a) Categorical Encoding:\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Identify categorical columns\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "print('Categorical Columns : ', categorical_cols.tolist())\n",
        "\n",
        "# Apply Label Encoding to all categorical columns\n",
        "for col in categorical_cols: df[col] = LabelEncoder().fit_transform(df[col])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEgNs8yvrT_M",
        "outputId": "5795acab-4451-4417-e2a8-92625bad8fb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categorical Columns :  ['Gender', 'Marital_Status', 'Department', 'Job_Role', 'Overtime', 'Attrition']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#b) Split the Data :\n",
        "\n",
        "# Set 'y' as the target () and drop it from X\n",
        "X = df.drop('Attrition', axis=1)\n",
        "y = df['Attrition']"
      ],
      "metadata": {
        "id": "EA-v-TwUwhNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#c) Training and Testing Sets:\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data into 75% training and 25% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "Q0v1SyLJBAL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Apply Machine Learning Algorithms:\n"
      ],
      "metadata": {
        "id": "uIcGM01rBaNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#a) K-Nearest Neighbors (KNN): K = 5\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Initialize KNN model with 5 neighbors\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Train the model using the training data\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Predict the target values for the test set\n",
        "y_pred_knn = knn.predict(X_test)"
      ],
      "metadata": {
        "id": "P-1hyZt3CTzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#b) Naive Bayes:\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Initialize the Naive Bayes model\n",
        "nb = GaussianNB()\n",
        "\n",
        "# Train the model on the training data\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "# Predict the target values for the test set\n",
        "y_pred_nb = nb.predict(X_test)"
      ],
      "metadata": {
        "id": "2A8pQfUdCvIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#c) Additional Models :\n",
        "#  I) Decision Tree , II) Support Vector Machine (SVM) , III) Random Forest\n",
        "\n",
        "\n",
        "# I) Decision Tree:\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize the Decision Tree model\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the model using the training data\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Predict the target values for the test set\n",
        "y_pred_dt = dt.predict(X_test)\n",
        "\n",
        "#---------------------------------------------------------------\n",
        "\n",
        "# II) Support Vector Machine (SVM) :\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Initialize the SVM model (using default RBF kernel)\n",
        "svm = SVC(random_state=42)\n",
        "\n",
        "# Train the model on the training data\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Predict the target values for the test set\n",
        "y_pred_svm = svm.predict(X_test)\n",
        "\n",
        "#---------------------------------------------------------------\n",
        "\n",
        "# III) Random Forest :\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize the Random Forest model\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Train the model using the training data\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict the target values for the test set\n",
        "y_pred_rf = rf.predict(X_test)"
      ],
      "metadata": {
        "id": "6G8nazWRDBwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#d)Bonus: Deep Learning Model :\n",
        "\n",
        "#  Feedforward Neural Network/Multilayer Perceptron (MLP).\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Scale features for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the model\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_scaled, y_train, epochs=20, batch_size=32, verbose=1, validation_split=0.2)\n",
        "\n",
        "# Predict the target values for the test set\n",
        "y_pred_dl_prob = model.predict(X_test_scaled)\n",
        "y_pred_dl = (y_pred_dl_prob > 0.5).astype(int).flatten()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PevsRBlGNwu",
        "outputId": "678d6afb-244a-44de-cefb-51b2e1ada740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.3569 - loss: 0.8270 - val_accuracy: 0.7600 - val_loss: 0.5675\n",
            "Epoch 2/20\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7653 - loss: 0.5600 - val_accuracy: 0.8000 - val_loss: 0.5060\n",
            "Epoch 3/20\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8060 - loss: 0.5011 - val_accuracy: 0.8000 - val_loss: 0.5051\n",
            "Epoch 4/20\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8011 - loss: 0.4834 - val_accuracy: 0.8000 - val_loss: 0.5066\n",
            "Epoch 5/20\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8012 - loss: 0.4865 - val_accuracy: 0.8000 - val_loss: 0.5076\n",
            "Epoch 6/20\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7836 - loss: 0.4858 - val_accuracy: 0.8000 - val_loss: 0.5095\n",
            "Epoch 7/20\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8030 - loss: 0.4631 - val_accuracy: 0.8000 - val_loss: 0.5109\n",
            "Epoch 8/20\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7832 - loss: 0.4780 - val_accuracy: 0.8000 - val_loss: 0.5132\n",
            "Epoch 9/20\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7910 - loss: 0.4554 - val_accuracy: 0.8000 - val_loss: 0.5170\n",
            "Epoch 10/20\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7876 - loss: 0.4484 - val_accuracy: 0.8000 - val_loss: 0.5190\n",
            "Epoch 11/20\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8200 - loss: 0.4087 - val_accuracy: 0.8000 - val_loss: 0.5207\n",
            "Epoch 12/20\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8258 - loss: 0.3929 - val_accuracy: 0.8000 - val_loss: 0.5256\n",
            "Epoch 13/20\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8239 - loss: 0.4017 - val_accuracy: 0.8067 - val_loss: 0.5281\n",
            "Epoch 14/20\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8317 - loss: 0.3809 - val_accuracy: 0.8067 - val_loss: 0.5311\n",
            "Epoch 15/20\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8237 - loss: 0.3844 - val_accuracy: 0.8000 - val_loss: 0.5354\n",
            "Epoch 16/20\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8086 - loss: 0.3915 - val_accuracy: 0.8000 - val_loss: 0.5390\n",
            "Epoch 17/20\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7950 - loss: 0.4101 - val_accuracy: 0.8000 - val_loss: 0.5405\n",
            "Epoch 18/20\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8322 - loss: 0.3527 - val_accuracy: 0.8000 - val_loss: 0.5459\n",
            "Epoch 19/20\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8230 - loss: 0.3641 - val_accuracy: 0.7800 - val_loss: 0.5487\n",
            "Epoch 20/20\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8190 - loss: 0.3559 - val_accuracy: 0.7800 - val_loss: 0.5531\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Model evaluation:"
      ],
      "metadata": {
        "id": "1MnGXfn0O81u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#A) for each model we will evaluate:\n",
        "\n",
        "*   Accuracy\n",
        "*   Confusion Matrix\n",
        "*   Precision\n",
        "*   Recall"
      ],
      "metadata": {
        "id": "nu-FDDbuaJPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score"
      ],
      "metadata": {
        "id": "Sxdy5l12O7yG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN :\n",
        "print(\"K-Nearest Neighbors (KNN) Evaluation:\")\n",
        "\n",
        "#     Accuracy\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "print(\"Accuracy:\", accuracy_knn)\n",
        "\n",
        "#     Confusion Matrix\n",
        "conf_matrix_knn = confusion_matrix(y_test, y_pred_knn)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix_knn)\n",
        "\n",
        "#     Precision\n",
        "precision_knn = precision_score(y_test, y_pred_knn)\n",
        "print(\"Precision:\", precision_knn)\n",
        "\n",
        "#     Recall\n",
        "recall_knn = recall_score(y_test, y_pred_knn)\n",
        "print(\"Recall:\", recall_knn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0V6OkKVrQA7Z",
        "outputId": "334fe891-3929-408b-ca57-f8aa2115bb69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K-Nearest Neighbors (KNN) Evaluation:\n",
            "Accuracy: 0.816\n",
            "Confusion Matrix:\n",
            " [[200  12]\n",
            " [ 34   4]]\n",
            "Precision: 0.25\n",
            "Recall: 0.10526315789473684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Naive Bayes :\n",
        "print(\"Naive Bayes Evaluation:\")\n",
        "\n",
        "#     Accuracy\n",
        "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
        "print(\"Accuracy:\", accuracy_nb)\n",
        "\n",
        "#     Confusion Matrix\n",
        "conf_matrix_nb = confusion_matrix(y_test, y_pred_nb)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix_nb)\n",
        "\n",
        "#     Precision\n",
        "precision_nb = precision_score(y_test, y_pred_nb)\n",
        "print(\"Precision:\", precision_nb)\n",
        "\n",
        "#     Recall\n",
        "recall_nb = recall_score(y_test, y_pred_nb)\n",
        "print(\"Recall:\", recall_nb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6n0SCvVlQ9iI",
        "outputId": "ddf64e4f-0272-4a5a-c1b5-a2e7233fa0f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Evaluation:\n",
            "Accuracy: 0.848\n",
            "Confusion Matrix:\n",
            " [[212   0]\n",
            " [ 38   0]]\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree :\n",
        "print(\"Decision Tree Evaluation:\")\n",
        "\n",
        "#     Accuracy\n",
        "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
        "print(\"Accuracy:\", accuracy_dt)\n",
        "\n",
        "#     Confusion Matrix\n",
        "conf_matrix_dt = confusion_matrix(y_test, y_pred_dt)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix_dt)\n",
        "\n",
        "#     Precision\n",
        "precision_dt = precision_score(y_test, y_pred_dt)\n",
        "print(\"Precision:\", precision_dt)\n",
        "\n",
        "#     Recall\n",
        "recall_dt = recall_score(y_test, y_pred_dt)\n",
        "print(\"Recall:\", recall_dt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7rD49uYRA5X",
        "outputId": "a709a1e1-4eae-46e0-f93f-3713970f4790"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Evaluation:\n",
            "Accuracy: 0.68\n",
            "Confusion Matrix:\n",
            " [[162  50]\n",
            " [ 30   8]]\n",
            "Precision: 0.13793103448275862\n",
            "Recall: 0.21052631578947367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Support Vector Machine (SVM) :\n",
        "print(\"Support Vector Machine (SVM) Evaluation:\")\n",
        "\n",
        "#     Accuracy\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "print(\"Accuracy:\", accuracy_svm)\n",
        "\n",
        "#     Confusion Matrix\n",
        "conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix_svm)\n",
        "\n",
        "#     Precision\n",
        "precision_svm = precision_score(y_test, y_pred_svm)\n",
        "print(\"Precision:\", precision_svm)\n",
        "\n",
        "#     Recall\n",
        "recall_svm = recall_score(y_test, y_pred_svm)\n",
        "print(\"Recall:\", recall_svm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqwmutBRWxkM",
        "outputId": "96a04823-30a8-4324-e199-67b301e41057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Support Vector Machine (SVM) Evaluation:\n",
            "Accuracy: 0.848\n",
            "Confusion Matrix:\n",
            " [[212   0]\n",
            " [ 38   0]]\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest :\n",
        "print(\"Random Forest Evaluation:\")\n",
        "\n",
        "#     Accuracy\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print(\"Accuracy:\", accuracy_rf)\n",
        "\n",
        "#     Confusion Matrix\n",
        "conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix_rf)\n",
        "\n",
        "#     Precision\n",
        "precision_rf = precision_score(y_test, y_pred_rf)\n",
        "print(\"Precision:\", precision_rf)\n",
        "\n",
        "#     Recall\n",
        "recall_rf = recall_score(y_test, y_pred_rf)\n",
        "print(\"Recall:\", recall_rf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkA67gvJXYk_",
        "outputId": "6736e635-47a5-48ad-e380-1e1a4587d4a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Evaluation:\n",
            "Accuracy: 0.848\n",
            "Confusion Matrix:\n",
            " [[212   0]\n",
            " [ 38   0]]\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bonus : Deep Learning(MLP):\n",
        "print(\"Deep Learning (MLP) Evaluation:\")\n",
        "\n",
        "#     Accuracy\n",
        "accuracy_dl = accuracy_score(y_test, y_pred_dl)\n",
        "print(\"Accuracy:\", accuracy_dl)\n",
        "\n",
        "#     Confusion Matrix\n",
        "conf_matrix_dl = confusion_matrix(y_test, y_pred_dl)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix_dl)\n",
        "\n",
        "#     Precision\n",
        "precision_dl = precision_score(y_test, y_pred_dl)\n",
        "print(\"Precision:\", precision_dl)\n",
        "\n",
        "#     Recall\n",
        "recall_dl = recall_score(y_test, y_pred_dl)\n",
        "print(\"Recall:\", recall_dl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFTbStFZYEl7",
        "outputId": "facf9344-7ecd-461a-bc27-854779b5c0a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deep Learning (MLP) Evaluation:\n",
            "Accuracy: 0.848\n",
            "Confusion Matrix:\n",
            " [[212   0]\n",
            " [ 38   0]]\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#B) Comparison :"
      ],
      "metadata": {
        "id": "jlHPQQHlZM6V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**📌 Key Observations:**\n",
        "\n",
        "* Naive Bayes, SVM, Random Forest, and MLP achieved higher accuracy (82+%) , However , they failed to predict any positive cases, resulting in 0 precision and recall. This suggests these models are simply predicting the majority class (0), likely due to class imbalance.\n",
        "\n",
        "\n",
        "* Decision Tree attempted to classify both classes\n",
        " , had higher recall (21%), meaning it captured more true positives than any other model, even if accuracy(68%) was lower.\n",
        "\n",
        "* KNN was the most balanced overall:\n",
        "it predicted both classes, had a moderate accuracy (82%), and achieved precision (25%), which was the highest among all models — though its recall was low (~10%)."
      ],
      "metadata": {
        "id": "HaZLZdiHZ5-l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Performing Model:\n",
        "\n",
        "**K-Nearest Neighbors (KNN)**\n",
        "\n",
        "It’s the only model with a reasonable balance between predicting both classes and maintaining decent accuracy.\n",
        "\n",
        "Despite others having slightly better accuracy, they completely fail at identifying positive cases — rendering them ineffective for real-world use where false negatives matter (e.g., predicting employee attrition).\n",
        "\n",
        "KNN’s higher precision indicates that when it predicts a positive case, it’s more likely to be correct."
      ],
      "metadata": {
        "id": "3wf7jICHbEEa"
      }
    }
  ]
}